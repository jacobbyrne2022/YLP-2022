device cuda:0
time steps Y:       [0, 1, 2, 3, 4]
time steps theta:   [0, 1, 2, 3, 4]
no. of channels:    [16, 32, 64, 64]
no. of epochs:      100
ODE reg param:      0.0
Use checkpointing:  True
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
training on 40000 images ; validating on 10000 images
Training  251866  weights in  78  layers
optimizer = SGD with momentum=9.0e-01, weight_decay=4.0e-04, nesterov=0, batchSize=125
epoch     time      |runMean|   |runVar|    lr        |params|    avgLoss   acc       valLoss   valAcc   
1         105.1     2.37e+00    1.22e+01    1.00e-01  3.42e+00    1.82e+00  32.44     1.79e+00  34.22    
2         106.4     1.11e+00    5.49e-01    1.00e-01  2.64e+00    1.52e+00  44.38     1.54e+00  44.29    
3         107.2     6.98e-01    2.16e-01    1.00e-01  2.35e+00    1.34e+00  51.33     1.35e+00  50.91    
4         107.7     5.18e-01    1.40e-01    1.00e-01  2.11e+00    1.20e+00  56.79     1.41e+00  50.82    
5         107.7     4.27e-01    1.21e-01    1.00e-01  1.96e+00    1.10e+00  60.77     1.17e+00  58.78    
6         107.6     4.13e-01    8.92e-02    1.00e-01  1.89e+00    1.01e+00  63.90     1.19e+00  58.65    
7         107.8     3.17e-01    7.51e-02    1.00e-01  1.89e+00    9.50e-01  66.30     1.24e+00  60.07    
8         107.6     2.80e-01    5.46e-02    1.00e-01  1.88e+00    8.82e-01  68.75     1.63e+00  53.70    
9         107.5     2.12e-01    5.64e-02    1.00e-01  1.88e+00    8.30e-01  70.52     1.18e+00  60.97    
10        107.5     2.11e-01    4.43e-02    1.00e-01  1.88e+00    7.85e-01  72.12     8.73e-01  68.94    
11        107.5     2.31e-01    4.74e-02    1.00e-01  1.87e+00    7.47e-01  73.53     8.71e-01  69.53    
12        107.3     2.54e-01    4.83e-02    1.00e-01  1.88e+00    7.12e-01  75.20     7.91e-01  72.95    
13        107.3     2.35e-01    4.49e-02    1.00e-01  1.88e+00    6.78e-01  76.07     7.65e-01  74.29    
14        107.5     1.92e-01    3.42e-02    1.00e-01  1.92e+00    6.54e-01  77.33     1.09e+00  64.61    
15        107.3     2.36e-01    4.09e-02    1.00e-01  1.94e+00    6.34e-01  77.91     8.42e-01  72.34    
16        107.4     2.86e-01    3.90e-02    1.00e-01  1.94e+00    6.14e-01  78.69     8.54e-01  72.23    
17        107.4     2.66e-01    3.54e-02    1.00e-01  1.96e+00    5.97e-01  79.28     1.37e+00  62.00    
18        107.8     2.69e-01    4.10e-02    1.00e-01  1.98e+00    5.76e-01  80.05     1.27e+00  64.33    
19        107.8     2.60e-01    3.70e-02    1.00e-01  1.97e+00    5.59e-01  80.56     7.59e-01  74.95    
20        107.7     2.13e-01    3.09e-02    1.00e-01  1.98e+00    5.48e-01  81.12     7.63e-01  75.40    
21        107.7     2.06e-01    3.63e-02    1.00e-01  2.00e+00    5.36e-01  81.29     8.09e-01  72.39    
22        108.2     2.53e-01    3.56e-02    1.00e-01  2.01e+00    5.22e-01  81.93     7.02e-01  77.01    
23        108.1     2.75e-01    3.28e-02    1.00e-01  2.06e+00    5.14e-01  82.38     6.66e-01  77.48    
24        107.8     2.42e-01    3.35e-02    1.00e-01  2.06e+00    5.06e-01  82.58     6.94e-01  77.60    
25        108.0     2.17e-01    2.47e-02    1.00e-01  2.09e+00    4.90e-01  83.19     8.51e-01  73.06    
26        108.0     2.81e-01    3.28e-02    1.00e-01  2.10e+00    4.85e-01  83.25     1.04e+00  69.43    
27        108.5     2.88e-01    3.62e-02    1.00e-01  2.10e+00    4.73e-01  83.61     6.31e-01  79.62    
28        108.8     2.70e-01    3.32e-02    1.00e-01  2.12e+00    4.62e-01  84.11     7.00e-01  77.75    
29        108.7     2.12e-01    3.42e-02    1.00e-01  2.11e+00    4.53e-01  84.38     7.38e-01  77.14    
30        108.6     2.59e-01    3.31e-02    1.00e-01  2.18e+00    4.50e-01  84.55     1.07e+00  67.55    
31        108.3     2.78e-01    3.92e-02    1.00e-01  2.16e+00    4.41e-01  84.85     7.16e-01  78.19    
32        108.2     2.26e-01    2.93e-02    1.00e-01  2.15e+00    4.30e-01  85.23     8.23e-01  74.50    
33        108.3     2.31e-01    3.28e-02    1.00e-01  2.19e+00    4.27e-01  85.17     6.79e-01  78.36    
34        108.2     2.28e-01    2.66e-02    1.00e-01  2.19e+00    4.25e-01  85.32     7.31e-01  76.90    
35        108.4     2.17e-01    4.58e-02    1.00e-01  2.24e+00    4.19e-01  85.30     6.80e-01  78.05    
36        108.3     2.50e-01    3.88e-02    1.00e-01  2.23e+00    4.11e-01  85.59     6.96e-01  77.13    
37        108.3     2.43e-01    3.76e-02    1.00e-01  2.21e+00    3.99e-01  86.13     8.43e-01  74.70    
38        108.3     2.70e-01    4.31e-02    1.00e-01  2.23e+00    4.05e-01  86.03     6.46e-01  79.97    
39        108.3     2.64e-01    3.99e-02    1.00e-01  2.26e+00    3.93e-01  86.38     6.09e-01  80.34    
40        108.3     2.74e-01    2.61e-02    1.00e-01  2.26e+00    3.95e-01  86.25     6.86e-01  78.42    
41        108.1     2.70e-01    3.85e-02    1.00e-01  2.28e+00    3.81e-01  86.69     6.99e-01  78.73    
42        107.9     2.28e-01    4.27e-02    1.00e-01  2.29e+00    3.81e-01  86.79     6.03e-01  79.99    
43        107.8     2.11e-01    2.47e-02    1.00e-01  2.28e+00    3.75e-01  87.00     6.75e-01  77.98    
44        108.2     2.06e-01    3.10e-02    1.00e-01  2.28e+00    3.72e-01  86.99     7.32e-01  77.70    
45        108.1     2.40e-01    2.39e-02    1.00e-01  2.31e+00    3.66e-01  87.28     5.95e-01  81.05    
46        108.1     2.06e-01    3.21e-02    1.00e-01  2.31e+00    3.61e-01  87.42     8.20e-01  74.47    
47        108.4     2.60e-01    2.87e-02    1.00e-01  2.33e+00    3.59e-01  87.41     7.23e-01  78.10    
48        108.2     2.47e-01    3.19e-02    1.00e-01  2.37e+00    3.55e-01  87.64     1.39e+00  66.19    
49        108.0     2.47e-01    3.50e-02    1.00e-01  2.38e+00    3.59e-01  87.53     6.71e-01  78.67    
50        108.1     2.32e-01    4.97e-02    1.00e-01  2.33e+00    3.43e-01  88.11     5.90e-01  81.69    
51        108.4     2.20e-01    3.59e-02    1.00e-01  2.36e+00    3.42e-01  88.20     5.96e-01  80.58    
52        108.1     2.54e-01    2.75e-02    1.00e-01  2.38e+00    3.45e-01  88.00     7.08e-01  77.12    
53        108.2     2.71e-01    2.96e-02    1.00e-01  2.39e+00    3.42e-01  88.25     8.35e-01  76.09    
54        108.1     2.13e-01    3.11e-02    1.00e-01  2.42e+00    3.39e-01  88.17     5.15e-01  82.68    
55        108.2     2.24e-01    4.03e-02    1.00e-01  2.39e+00    3.31e-01  88.62     6.28e-01  79.65    
56        108.4     2.36e-01    3.46e-02    1.00e-01  2.37e+00    3.27e-01  88.66     5.46e-01  81.88    
57        108.3     2.88e-01    2.61e-02    1.00e-01  2.41e+00    3.29e-01  88.58     5.61e-01  81.37    
58        107.9     2.54e-01    3.17e-02    1.00e-01  2.40e+00    3.24e-01  88.64     5.38e-01  82.74    
59        107.9     3.04e-01    3.75e-02    1.00e-01  2.43e+00    3.23e-01  88.86     6.64e-01  78.92    
60        107.9     2.25e-01    1.69e-02    1.00e-01  2.44e+00    3.19e-01  88.99     5.47e-01  82.00    
61        108.2     2.84e-01    2.71e-02    2.00e-02  2.39e+00    3.20e-01  88.83     1.14e+00  71.10    
62        108.0     2.89e-01    3.55e-02    2.00e-02  2.41e+00    3.14e-01  89.16     5.10e-01  83.55    
63        108.0     2.35e-01    3.21e-02    2.00e-02  2.44e+00    3.10e-01  89.25     5.66e-01  82.15    
64        108.1     2.35e-01    3.94e-02    2.00e-02  2.44e+00    3.07e-01  89.28     5.85e-01  81.64    
65        108.1     2.51e-01    4.17e-02    2.00e-02  2.43e+00    3.00e-01  89.58     7.06e-01  79.19    
66        108.1     2.49e-01    3.49e-02    2.00e-02  2.47e+00    3.07e-01  89.26     8.29e-01  76.30    
67        108.3     2.15e-01    3.28e-02    2.00e-02  2.50e+00    3.01e-01  89.42     5.40e-01  83.45    
68        108.3     2.65e-01    2.89e-02    2.00e-02  2.48e+00    2.99e-01  89.53     8.84e-01  74.09    
69        108.2     2.43e-01    3.19e-02    2.00e-02  2.50e+00    2.98e-01  89.68     6.01e-01  80.71    
70        108.1     2.38e-01    3.70e-02    2.00e-02  2.50e+00    2.95e-01  89.69     6.25e-01  80.84    
71        108.0     2.93e-01    3.02e-02    2.00e-02  2.46e+00    2.90e-01  89.92     7.63e-01  77.73    
72        108.1     2.65e-01    2.22e-02    2.00e-02  2.51e+00    2.91e-01  90.00     7.32e-01  77.65    
73        107.9     3.36e-01    2.95e-02    2.00e-02  2.51e+00    2.88e-01  89.95     1.12e+00  71.26    
74        107.9     2.91e-01    3.71e-02    2.00e-02  2.52e+00    2.89e-01  89.82     1.14e+00  71.78    
75        107.9     2.42e-01    2.03e-02    2.00e-02  2.54e+00    2.88e-01  89.90     5.37e-01  82.65    
76        108.1     2.43e-01    2.48e-02    2.00e-02  2.53e+00    2.88e-01  89.89     6.97e-01  80.48    
77        107.7     2.16e-01    2.67e-02    2.00e-02  2.54e+00    2.86e-01  90.09     7.77e-01  77.29    
78        107.9     2.16e-01    3.09e-02    2.00e-02  2.50e+00    2.81e-01  90.39     5.77e-01  82.69    
79        107.9     2.75e-01    3.87e-02    2.00e-02  2.53e+00    2.83e-01  90.21     7.70e-01  77.04    
80        107.8     2.46e-01    3.75e-02    2.00e-02  2.51e+00    2.75e-01  90.58     6.82e-01  79.89    
81        108.2     2.44e-01    3.08e-02    4.00e-03  2.56e+00    2.75e-01  90.36     5.74e-01  82.25    
82        108.0     2.58e-01    3.05e-02    4.00e-03  2.54e+00    2.77e-01  90.40     5.98e-01  81.79    
83        108.0     2.58e-01    2.02e-02    4.00e-03  2.52e+00    2.70e-01  90.63     6.78e-01  80.38    
84        107.9     3.44e-01    3.39e-02    4.00e-03  2.55e+00    2.70e-01  90.65     7.20e-01  79.55    
85        108.0     2.70e-01    3.25e-02    4.00e-03  2.56e+00    2.70e-01  90.46     1.18e+00  69.97    
86        108.0     2.66e-01    3.02e-02    4.00e-03  2.54e+00    2.73e-01  90.48     6.25e-01  81.24    
87        107.9     2.39e-01    3.51e-02    4.00e-03  2.53e+00    2.67e-01  90.82     7.07e-01  79.31    
88        108.0     2.65e-01    2.85e-02    4.00e-03  2.56e+00    2.67e-01  90.62     9.25e-01  75.70    
89        107.9     2.96e-01    2.53e-02    4.00e-03  2.56e+00    2.65e-01  90.84     4.77e-01  85.37    
90        107.9     2.46e-01    2.90e-02    4.00e-03  2.57e+00    2.63e-01  90.88     9.05e-01  74.28    
91        107.9     2.19e-01    2.61e-02    4.00e-03  2.59e+00    2.64e-01  90.73     6.03e-01  81.84    
92        107.9     2.28e-01    2.61e-02    4.00e-03  2.55e+00    2.58e-01  90.97     4.81e-01  84.97    
93        108.1     3.03e-01    4.13e-02    4.00e-03  2.57e+00    2.61e-01  90.85     9.50e-01  74.49    
94        108.0     2.52e-01    3.40e-02    4.00e-03  2.58e+00    2.56e-01  91.21     6.52e-01  81.01    
95        107.9     2.34e-01    3.18e-02    4.00e-03  2.57e+00    2.55e-01  91.13     9.74e-01  73.92    
96        108.4     2.68e-01    2.70e-02    4.00e-03  2.62e+00    2.53e-01  91.10     1.03e+00  74.68    
97        108.3     2.97e-01    2.48e-02    4.00e-03  2.60e+00    2.54e-01  91.29     5.88e-01  82.47    
98        108.1     2.86e-01    3.31e-02    4.00e-03  2.62e+00    2.49e-01  91.28     7.63e-01  77.82    
99        108.1     2.84e-01    2.14e-02    4.00e-03  2.62e+00    2.55e-01  91.06     5.60e-01  83.17    
100       108.1     3.28e-01    3.00e-02    4.00e-03  2.62e+00    2.49e-01  91.30     5.67e-01  82.65    
Time elapsed:  10819.085258960724
Training complete. Now testing...

testing loss: 4.97e-01     testing accuracy: 84.71    
Files already downloaded and verified

 eps: -0.10     testing loss: 6.35e-01     testing accuracy: 80.82      acc retention: 95.41    
Files already downloaded and verified

 eps: -0.03     testing loss: 5.21e-01     testing accuracy: 84.29      acc retention: 99.50    
Files already downloaded and verified

 eps: -0.01     testing loss: 5.02e-01     testing accuracy: 84.76      acc retention: 100.06   
Files already downloaded and verified

 eps: 0.00      testing loss: 4.99e-01     testing accuracy: 84.72      acc retention: 100.01   
Files already downloaded and verified

 eps: 0.01      testing loss: 4.99e-01     testing accuracy: 84.79      acc retention: 100.09   
Files already downloaded and verified

 eps: 0.03      testing loss: 5.19e-01     testing accuracy: 84.10      acc retention: 99.28    
Files already downloaded and verified

 eps: 0.10      testing loss: 7.79e-01     testing accuracy: 78.02      acc retention: 92.10    
RKNet(
  (dynamicBlocks): ModuleList(
    (0): rk4(
      (controlLayers): ModuleList(
        (0): DoubleSymLayer(
          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): DoubleSymLayer(
          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (2): DoubleSymLayer(
          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (3): DoubleSymLayer(
          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (4): DoubleSymLayer(
          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (1): rk4(
      (controlLayers): ModuleList(
        (0): DoubleSymLayer(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): DoubleSymLayer(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (2): DoubleSymLayer(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (3): DoubleSymLayer(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (4): DoubleSymLayer(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (2): rk4(
      (controlLayers): ModuleList(
        (0): DoubleSymLayer(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): DoubleSymLayer(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (2): DoubleSymLayer(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (3): DoubleSymLayer(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (4): DoubleSymLayer(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): ReLU()
          (normLayer): TvNorm()
          (convt): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
  )
  (connectors): ModuleList(
    (0): ConnectingLayer(
      (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))
      (act): ReLU()
      (normLayer): BatchNorm2d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ConnectingLayer(
      (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
      (act): ReLU()
      (normLayer): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ConnectingLayer(
      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (act): ReLU()
      (normLayer): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (open): ConnectingLayer(
    (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (act): ReLU()
    (normLayer): BatchNorm2d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (linear): Linear(in_features=64, out_features=10, bias=True)
)
